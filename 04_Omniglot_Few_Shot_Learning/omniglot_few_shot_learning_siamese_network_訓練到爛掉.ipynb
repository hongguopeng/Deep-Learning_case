{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"siamese_network.png\" style=\"width:953px;height:600px;float:middle\">\n",
    "以上為siamese network的計算流程<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請解壓縮data.rar，取得本程式之數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_num = 20\n",
    "img_width , img_height , channels = 28 , 28 , 1\n",
    "way_num = 60\n",
    "base_num = 5\n",
    "input_num = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "def load_data(root_dir):\n",
    "    img_dirs = []\n",
    "    for folder in os.listdir(root_dir):\n",
    "        for character_folder in os.listdir(root_dir + '/{}'.format(folder)):\n",
    "            img_dirs.append(os.path.join(root_dir , folder , character_folder))\n",
    "\n",
    "    dataset = np.zeros([len(img_dirs) , examples_num , img_height , img_width] , dtype = np.float32)\n",
    "    for i , folder in enumerate(img_dirs):\n",
    "        for j , file in enumerate(os.listdir(folder)):\n",
    "            imagePath = os.path.join(folder , file)\n",
    "            image = Image.open(imagePath).resize((img_width , img_height))\n",
    "            values = 1. - np.array(image , np.float32)\n",
    "            dataset[i , j , : , :] = values\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = load_data('./data/training_image')\n",
    "test_dataset = load_data('./data/testing_image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range = 25,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1 ,\n",
    "                         shear_range = 0.2 ,\n",
    "                         zoom_range = 0.2,\n",
    "                         fill_mode = 'nearest')\n",
    "\n",
    "def get_batch(data , way_num = 60 , input_num = 7 , base_num = 5):\n",
    "\n",
    "    class_indices = np.random.choice(np.arange(len(data)) ,\n",
    "                                     size = way_num ,\n",
    "                                     replace = False)\n",
    "\n",
    "    base_image_set = None\n",
    "    input_image_set = None\n",
    "    input_label_set = None\n",
    "    for i , class_index in enumerate(class_indices):\n",
    "\n",
    "        class_image = np.reshape(data[class_index] , [20 , 28 , 28 , 1])\n",
    "        augmentation_data = aug.flow(np.reshape(class_image , [-1 , 28 , 28 , 1]) , np.arange(20))\n",
    "        class_image = augmentation_data[0][0]\n",
    "\n",
    "        sample_index = np.random.choice(np.arange(20) ,\n",
    "                                        size = input_num + base_num ,\n",
    "                                        replace = False)\n",
    "\n",
    "        # base_image → [1 , 5 , 28 , 28 , 1]\n",
    "        base_index = sample_index[:base_num]\n",
    "        base_image = np.reshape(class_image[base_index] , [1 , base_num , 28 , 28 , 1])\n",
    "        if base_image_set is None:\n",
    "            base_image_set = base_image\n",
    "        else:\n",
    "            # base_image_set → [60 , 5 , 28 , 28 , 1] (執行迴圈60次，沿著axis 0，將base_image堆疊60次)\n",
    "            # 總共60個class，每1個class有5張image\n",
    "            base_image_set = np.concatenate([base_image_set , base_image] , axis = 0)\n",
    "\n",
    "        input_index = sample_index[-input_num:]\n",
    "        # input_image → [7 , 28 , 28 , 1]\n",
    "        input_image = np.reshape(class_image[input_index] , [1 , input_num , 28 , 28 , 1])\n",
    "        if input_image_set is None:\n",
    "            input_image_set = input_image\n",
    "        else:\n",
    "            # input_image_set → [60 , 7 , 28 , 28 , 1] (執行迴圈60次，沿著axis 0，將input_image堆疊60次)\n",
    "            # 總共60個class，每1個class有7張image\n",
    "            input_image_set = np.concatenate([input_image_set , input_image] , axis = 0)\n",
    "\n",
    "        # input_label → [1 , 7 , 60]\n",
    "        # class 0的input_label[: , : , 0] = 1\n",
    "        # class 為1的input_label[: , : , 1] = 1\n",
    "        #                   ...\n",
    "        # class 為59的input_label[: , : , 60] = 1\n",
    "        input_label = np.zeros([1 , input_num , way_num])\n",
    "        input_label[: , : , i] = 1\n",
    "        if input_label_set is None:\n",
    "            input_label_set = input_label\n",
    "        else:\n",
    "            # input_label_set → [60 , 7 , 60] (執行迴圈60次，沿著axis 0，將input_label堆疊60次)\n",
    "            # 總共60個class，每1個class含有相同的7個相同的label，而每1個label的one-hot的深度當然為60\n",
    "            input_label_set = np.concatenate([input_label_set , input_label] , axis = 0)\n",
    "\n",
    "    return base_image_set , input_image_set , input_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = tf.placeholder(tf.float32 , [way_num , input_num , 28 , 28 , 1])\n",
    "input_image_ = tf.reshape(input_image , [-1 , 28 , 28 , 1])\n",
    "\n",
    "base_image = tf.placeholder(tf.float32 , [way_num , base_num , 28 , 28 , 1])\n",
    "base_image_ = tf.reshape(base_image , [-1 , 28 , 28 , 1])\n",
    "\n",
    "y_true = tf.placeholder(tf.float32 , [way_num , input_num , way_num])\n",
    "y_true_ = tf.reshape(y_true , [-1 , way_num])\n",
    "\n",
    "on_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm_layer_part1(inputs , on_train , convolution):\n",
    "    # the dimension you wanna normalize, here [0] for batch\n",
    "    # for image, you wanna do [0 , 1 , 2] for [batch , height , width] but not channel\n",
    "    if convolution:\n",
    "        fc_mean , fc_var = tf.nn.moments(inputs , axes = [0 , 1 , 2] , name = 'mean_var')\n",
    "    else:\n",
    "        fc_mean , fc_var = tf.nn.moments(inputs , axes = [0] , name = 'mean_var')\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay = 0.99)\n",
    "    ema_apply_op = ema.apply([fc_mean , fc_var])\n",
    "    mean = tf.cond(on_train , lambda : fc_mean , lambda : ema.average(fc_mean))\n",
    "    var = tf.cond(on_train , lambda : fc_var , lambda : ema.average(fc_var))\n",
    "    return mean , var , ema_apply_op\n",
    "\n",
    "def batch_norm_layer_part2(inputs , mean , var):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    scale = tf.get_variable(initializer = tf.ones([1 , inputs.shape[-1].value]) , name = 'scale')\n",
    "    shift = tf.get_variable(initializer = tf.zeros([1 , inputs.shape[-1].value]) , name = 'shift')\n",
    "    temp = (inputs - mean) / tf.sqrt(var + 1e-8)\n",
    "    outputs = tf.multiply(temp , scale) + shift\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(input_ , reuse = False):\n",
    "    \n",
    "    #------------------------------conv_layer------------------------------#\n",
    "    ema_list = []\n",
    "    for i in range(1 , 6):\n",
    "        with tf.variable_scope('conv{}'.format(i)) as scope:\n",
    "            if reuse : tf.get_variable_scope().reuse_variables()\n",
    "            conv_output = tf.contrib.layers.conv2d(input_ , 64 , [3 , 3] ,\n",
    "                                                   activation_fn = tf.nn.relu , padding='SAME' ,\n",
    "                                                   weights_initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    \n",
    "        with tf.variable_scope('conv{}_compute_mean_var'.format(i)):\n",
    "            conv_mean , conv_var , conv_ema = batch_norm_layer_part1(conv_output , on_train , True)\n",
    "    \n",
    "        with tf.variable_scope(scope):\n",
    "            conv_bn = batch_norm_layer_part2(conv_output , conv_mean , conv_var)\n",
    "            conv_pooling = tf.contrib.layers.max_pool2d(conv_bn , [2 , 2] , padding = 'SAME')\n",
    "\n",
    "        input_ = conv_pooling\n",
    "        ema_list.append(conv_ema)\n",
    "\n",
    "    update_ema = tf.group(ema_list)\n",
    "    #------------------------------conv_layer------------------------------#\n",
    "    \n",
    "\n",
    "    #------------------------------flatten_layer------------------------------#\n",
    "    with tf.variable_scope('flatten'):\n",
    "        output_flatten = tf.contrib.layers.flatten(input_)\n",
    "    #------------------------------flatten_layer------------------------------#\n",
    "        \n",
    "    return output_flatten , update_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Hong Guo-Peng\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Hong Guo-Peng\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Hong Guo-Peng\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('feature_extractor'):\n",
    "    # embedding_input → [60 * 7 , 64]\n",
    "    embedding_input , ema_input = feature_extractor(input_image_ , reuse = False)\n",
    "    # embedding_input → [60 , 60 * 7 , 64]\n",
    "    embedding_input_copy = tf.tile(tf.expand_dims(embedding_input , axis = 0) , [way_num , 1 , 1])\n",
    "\n",
    "    # embedding_base → [60 , 5 , 64]    \n",
    "    embedding_base , ema_base = feature_extractor(base_image_ , reuse = True)\n",
    "    embedding_base = tf.reshape(embedding_base , [-1 , base_num , embedding_base.shape[-1].value])\n",
    "    # embedding_base_mean → [60 , 64]  \n",
    "    embedding_base_mean = tf.reduce_mean(embedding_base , axis = 1)\n",
    "    # embedding_base_copy → [60 , 60 * 7 , 64] \n",
    "    embedding_base_copy = tf.tile(tf.expand_dims(embedding_base_mean , axis = 1) , [1 , way_num * input_num , 1])\n",
    "\n",
    "    update_ema = tf.group([ema_input , ema_base])\n",
    "\n",
    "\n",
    "with tf.variable_scope('euclidean_distance'):\n",
    "    distance = tf.reduce_sum(tf.pow(embedding_base_copy - embedding_input_copy , 2) , axis = -1)\n",
    "    distance = tf.transpose(distance , [1 , 0])\n",
    "    distance = tf.sqrt(tf.maximum(distance , 1e-9))\n",
    "\n",
    "    \n",
    "with tf.variable_scope('contrastive_loss'):\n",
    "    margin = 4\n",
    "    decision_similarity = y_true_\n",
    "    similarity = tf.multiply(decision_similarity , tf.square(distance))\n",
    "    dissimilarity = tf.multiply(1 - decision_similarity , -tf.square(distance))\n",
    "    contrastive_loss = tf.reduce_mean(similarity + dissimilarity)\n",
    "    \n",
    "    \n",
    "with tf.variable_scope('optimizer'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(contrastive_loss)\n",
    "    \n",
    "    \n",
    "with tf.variable_scope('accuracy'):    \n",
    "    correct = tf.equal(tf.argmin(distance , 1) , tf.argmax(y_true_ , 1))\n",
    "    correct = tf.cast(correct , tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "batch_i : 0\n",
      "training_loss : -121.8945\n",
      "training_accuracy : 6.67%\n",
      "******************************\n",
      "testing_loss : -425789587456.0000\n",
      "testing_accuracy : 6.19%\n",
      "\n",
      "==============================\n",
      "batch_i : 160\n",
      "training_loss : -635.0869\n",
      "training_accuracy : 9.05%\n",
      "******************************\n",
      "testing_loss : -301.0881\n",
      "testing_accuracy : 6.43%\n",
      "\n",
      "==============================\n",
      "batch_i : 320\n",
      "training_loss : -840.5331\n",
      "training_accuracy : 5.48%\n",
      "******************************\n",
      "testing_loss : -375.4400\n",
      "testing_accuracy : 7.38%\n",
      "\n",
      "==============================\n",
      "batch_i : 480\n",
      "training_loss : -1146.9990\n",
      "training_accuracy : 7.14%\n",
      "******************************\n",
      "testing_loss : -438.3100\n",
      "testing_accuracy : 5.00%\n",
      "\n",
      "==============================\n",
      "batch_i : 640\n",
      "training_loss : -1483.4766\n",
      "training_accuracy : 7.62%\n",
      "******************************\n",
      "testing_loss : -663.0653\n",
      "testing_accuracy : 7.86%\n",
      "\n",
      "==============================\n",
      "batch_i : 800\n",
      "training_loss : -1896.4108\n",
      "training_accuracy : 4.29%\n",
      "******************************\n",
      "testing_loss : -369.8025\n",
      "testing_accuracy : 5.24%\n",
      "\n",
      "==============================\n",
      "batch_i : 960\n",
      "training_loss : -2291.2598\n",
      "training_accuracy : 5.24%\n",
      "******************************\n",
      "testing_loss : -1088.8358\n",
      "testing_accuracy : 5.95%\n",
      "\n",
      "==============================\n",
      "batch_i : 1120\n",
      "training_loss : -2673.9512\n",
      "training_accuracy : 7.14%\n",
      "******************************\n",
      "testing_loss : -2350.5640\n",
      "testing_accuracy : 7.14%\n",
      "\n",
      "==============================\n",
      "batch_i : 1280\n",
      "training_loss : -3199.5688\n",
      "training_accuracy : 5.24%\n",
      "******************************\n",
      "testing_loss : -223.7636\n",
      "testing_accuracy : 3.57%\n",
      "\n",
      "==============================\n",
      "batch_i : 1440\n",
      "training_loss : -3757.8640\n",
      "training_accuracy : 6.90%\n",
      "******************************\n",
      "testing_loss : -441.2281\n",
      "testing_accuracy : 4.29%\n",
      "\n",
      "==============================\n",
      "batch_i : 1600\n",
      "training_loss : -4333.9297\n",
      "training_accuracy : 9.29%\n",
      "******************************\n",
      "testing_loss : -72.0956\n",
      "testing_accuracy : 3.10%\n",
      "\n",
      "==============================\n",
      "batch_i : 1760\n",
      "training_loss : -4997.1836\n",
      "training_accuracy : 7.38%\n",
      "******************************\n",
      "testing_loss : -1867.2552\n",
      "testing_accuracy : 4.29%\n",
      "\n",
      "==============================\n",
      "batch_i : 1920\n",
      "training_loss : -5567.6177\n",
      "training_accuracy : 4.76%\n",
      "******************************\n",
      "testing_loss : -424.4562\n",
      "testing_accuracy : 3.33%\n",
      "\n",
      "==============================\n",
      "batch_i : 2080\n",
      "training_loss : -6057.9966\n",
      "training_accuracy : 5.48%\n",
      "******************************\n",
      "testing_loss : -151.2541\n",
      "testing_accuracy : 2.14%\n",
      "\n",
      "==============================\n",
      "batch_i : 2240\n",
      "training_loss : -7016.4097\n",
      "training_accuracy : 7.38%\n",
      "******************************\n",
      "testing_loss : -50.9386\n",
      "testing_accuracy : 2.86%\n",
      "\n",
      "==============================\n",
      "batch_i : 2400\n",
      "training_loss : -8005.7891\n",
      "training_accuracy : 9.76%\n",
      "******************************\n",
      "testing_loss : -185.3329\n",
      "testing_accuracy : 3.10%\n",
      "\n",
      "==============================\n",
      "batch_i : 2560\n",
      "training_loss : -6668.1782\n",
      "training_accuracy : 7.14%\n",
      "******************************\n",
      "testing_loss : -539.7303\n",
      "testing_accuracy : 4.05%\n",
      "\n",
      "==============================\n",
      "batch_i : 2720\n",
      "training_loss : -9491.6016\n",
      "training_accuracy : 5.00%\n",
      "******************************\n",
      "testing_loss : -166.4289\n",
      "testing_accuracy : 1.67%\n",
      "\n",
      "==============================\n",
      "batch_i : 2880\n",
      "training_loss : -10668.5166\n",
      "training_accuracy : 7.62%\n",
      "******************************\n",
      "testing_loss : -306.4249\n",
      "testing_accuracy : 3.81%\n",
      "\n",
      "==============================\n",
      "batch_i : 3040\n",
      "training_loss : -11641.0479\n",
      "training_accuracy : 7.14%\n",
      "******************************\n",
      "testing_loss : -607.2677\n",
      "testing_accuracy : 3.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "embedding_vector_list = []\n",
    "for batch_i in range(0 , 3200):\n",
    "    base_image_batch , input_image_batch , input_label_batch = get_batch(train_dataset)\n",
    "\n",
    "    _  , _ , train_loss , train_accuracy = sess.run([train_op , update_ema , contrastive_loss , accuracy] ,\n",
    "                                                     feed_dict = {input_image : input_image_batch ,\n",
    "                                                                  y_true : input_label_batch ,\n",
    "                                                                  base_image : base_image_batch ,\n",
    "                                                                  on_train : True})\n",
    "    \n",
    "    if batch_i % 160 == 0:\n",
    "        print('=' * 30)\n",
    "        print('batch_i : {}'.format(batch_i))\n",
    "        print('training_loss : {:.4f}'.format(train_loss))\n",
    "        print('training_accuracy : {:.2%}'.format(train_accuracy))\n",
    "\n",
    "        base_image_test , input_image_test , input_label_test = get_batch(test_dataset)\n",
    "        test_loss , test_accuracy =  sess.run([contrastive_loss , accuracy] ,\n",
    "                                              feed_dict = {input_image : input_image_test ,\n",
    "                                                           y_true : input_label_test ,\n",
    "                                                           base_image : base_image_test ,\n",
    "                                                           on_train : False})\n",
    "        print('*' * 30)\n",
    "        print('testing_loss : {:.4f}'.format(test_loss))\n",
    "        print('testing_accuracy : {:.2%}\\n'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
