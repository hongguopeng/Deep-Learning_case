{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Multi-Label.png\" style=\"width:1120px;height:300px;float:middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上為Multi-Label的計算流程<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改變initializer，在訓練的過程中即可降低loss\n",
    "\n",
    "使用tf.contrib.layers.xavier_initializer() 或 tf.glorot_uniform_initializer()，都可以讓training loss下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請解壓縮data.rar，取得本程式之數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數\n",
    "EPOCHS = 50\n",
    "LR = 1e-3\n",
    "BS = 32\n",
    "IMAGE_DIMS = [96 , 96 , 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取檔案之前，請直接解壓縮dataset.rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label : 0 , class : black\n",
      "label : 1 , class : blue\n",
      "label : 2 , class : dress\n",
      "label : 3 , class : jeans\n",
      "label : 4 , class : red\n",
      "label : 5 , class : shirt\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 獲取數據路徑\n",
    "image_types = ['.jpg' , '.jpeg' , '.png' , '.bmp' , '.tif' , '.tiff'] # 只要副檔名符合image_types中的任何一個都當作訓練資料\n",
    "imagePaths = [] \n",
    "image_num = {}\n",
    "for files in os.listdir('./dataset'):\n",
    "    # 計算每個資料夾image的數目    \n",
    "    image_num[files] = len(os.listdir('./dataset/{}'.format(files))) \n",
    "    for image in os.listdir('./dataset/{}'.format(files)):\n",
    "        # os.path.splitext(image) => 獲取image的副檔名\n",
    "        if os.path.splitext(image)[-1].lower() in image_types:\n",
    "            imagePaths.append('./dataset/{}/{}'.format(files , image))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# 繪圖看一下每個資料夾的image的數目的分布情形\n",
    "fig , ax = plt.subplots(1 , 1 , figsize = (20 , 10))\n",
    "ax.bar(image_num.keys() , image_num.values() , alpha = 0.5 , width = 0.5 , facecolor = 'pink' , edgecolor = 'black')\n",
    "ax.set_xlabel('Class' , fontsize = 30)\n",
    "ax.set_ylabel('ImageNnumber' , fontsize = 30)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "\n",
    "\n",
    "# 獲取數據標簽\n",
    "data , labels = [] , []\n",
    "for imagePath in imagePaths:\n",
    "    # 讀取image，並將image做resize\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1] , IMAGE_DIMS[0]))\n",
    "    data.append(image)\n",
    "    \n",
    "    # 服裝顏色 => label[0]    服裝種類 => label[1]   \n",
    "    label = imagePath.split('/')[-2].split('_')\n",
    "    labels.append(label)\n",
    "\n",
    "    \n",
    "# 將讀取到的image做預處理    \n",
    "data = np.array(data , dtype = 'float') / 255.0\n",
    "data = data.astype('float32')\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "# 制作標簽(以下為MultiLabel的示意說明)\n",
    "#              blue  black  red  shirt  dress  jeans\n",
    "# label_1 =>    1     0      0     1      0      0\n",
    "# label_2 =>    0     1      0     0      1      0 \n",
    "# label_3 =>    0     0      1     0      0      1 \n",
    "# 每筆data的label在服裝顏色與服裝種類分別都會有1個1\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels = mlb.fit_transform(labels).astype('float32')  \n",
    "for i , label in enumerate(mlb.classes_):\n",
    "    print('label : {} , class : {}'.format(i , label))\n",
    "\n",
    "    \n",
    "# 數據集切分\n",
    "(trainX , testX , trainY , testY) = train_test_split(data ,\n",
    "                                                     labels , \n",
    "                                                     test_size = 0.2 , \n",
    "                                                     random_state = 42)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每個資料夾image的數目看起來還算均勻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    # tf.contrib.layers.xavier_initializer() 與 tf.glorot_uniform_initializer() 效果都差不多 !!\n",
    "    # 不過使用tf.truncated_normal(shape , stddev = 0.0001)，根本train不起來\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initializer = tf.constant(0.0001 , shape = shape)\n",
    "    return tf.Variable(initializer)\n",
    "\n",
    "def conv2d(x , W):\n",
    "    # stride [1, x_movement , y_movement, 1]\n",
    "    # Must have strides[0] = strides[3] = 1\n",
    "    return tf.nn.conv2d(x , W , strides = [1 , 1 , 1 , 1] , padding = 'SAME') \n",
    "\n",
    "def max_pool(x , k , s):\n",
    "    # 不需要跟tf.nn.conv2d一樣要輸入W\n",
    "    # ksize = [1 , *2* , *2* , 1] 輸入 2 , 2 代表每2x2個pixel做一次選取pixel最大的動作\n",
    "    # stride [1, x_movement, y_movement, 1]\n",
    "    return tf.nn.max_pool(x , ksize = [1 , k , k , 1] , strides = [1 , s , s , 1] , padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-e135b15616cc>:15: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-5-e135b15616cc>:48: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Hong Guo-Peng\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "# input layer\n",
    "xs = tf.placeholder(tf.float32 , [None , IMAGE_DIMS[0] , IMAGE_DIMS[0] , IMAGE_DIMS[2]])\n",
    "ys = tf.placeholder(tf.int32 , [None , 6])\n",
    "on_train = tf.placeholder(tf.bool) # train/test selector for dropout\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "with tf.variable_scope('classfication_for_color_and_clothing'):\n",
    "    # conv1 layer \n",
    "    conv_w_1 = weight_variable([3 , 3 , 3 , 32]) \n",
    "    conv_b_1 = bias_variable([32])\n",
    "    conv_output_1 = tf.nn.relu(conv2d(xs , conv_w_1) + conv_b_1) \n",
    "    conv_pooling_1 = max_pool(conv_output_1 , k = 3 , s = 3)\n",
    "    conv_dropout_1 = tf.cond(on_train , \n",
    "                             lambda : tf.nn.dropout(conv_pooling_1 , keep_prob = 0.9) , \n",
    "                             lambda : tf.nn.dropout(conv_pooling_1 , keep_prob = 1))\n",
    "\n",
    "\n",
    "    # conv2 layer \n",
    "    conv_w_2 = weight_variable([3 , 3 , 32 , 64]) \n",
    "    conv_b_2 = bias_variable([64])\n",
    "    conv_output_2 = tf.nn.relu(conv2d(conv_dropout_1 , conv_w_2) + conv_b_2)\n",
    "\n",
    "\n",
    "    # conv3 layer \n",
    "    conv_w_3 = weight_variable([3 , 3 , 64 , 64]) \n",
    "    conv_b_3 = bias_variable([64])\n",
    "    conv_output_3 = tf.nn.relu(conv2d(conv_output_2 , conv_w_3) + conv_b_3) \n",
    "    conv_pooling_3 = max_pool(conv_output_3 , k = 2 , s = 2)\n",
    "    conv_dropout_3 = tf.cond(on_train ,\n",
    "                             lambda : tf.nn.dropout(conv_pooling_3 , keep_prob = 0.9) , \n",
    "                             lambda : tf.nn.dropout(conv_pooling_3 , keep_prob = 1))\n",
    "\n",
    "    # conv4 layer \n",
    "    conv_w_4 = weight_variable([3 , 3 , 64 , 128]) \n",
    "    conv_b_4 = bias_variable([128])\n",
    "    conv_output_4 = tf.nn.relu(conv2d(conv_dropout_3 , conv_w_4) + conv_b_4) \n",
    "\n",
    "\n",
    "    # conv5 layer \n",
    "    conv_w_5 = weight_variable([3 , 3 , 128 , 128]) \n",
    "    conv_b_5 = bias_variable([128])\n",
    "    conv_output_5 = tf.nn.relu(conv2d(conv_output_4 , conv_w_5) + conv_b_5) \n",
    "    conv_pooling_5 = max_pool(conv_output_5 , k = 2 , s = 2)\n",
    "    conv_dropout_5 = tf.cond(on_train , \n",
    "                             lambda : tf.nn.dropout(conv_pooling_5 , keep_prob = 0.9) , \n",
    "                             lambda : tf.nn.dropout(conv_pooling_5 , keep_prob = 1))\n",
    "    conv_dropout_5_flatten = tf.layers.flatten(conv_dropout_5)\n",
    "\n",
    "\n",
    "    # fully connected layer 1\n",
    "    fc_w_1 = weight_variable([conv_dropout_5_flatten.shape[1].value , 1024])\n",
    "    fc_b_1 = bias_variable([1024])\n",
    "    fc_output_1 = tf.nn.relu(tf.matmul(conv_dropout_5_flatten , fc_w_1) + fc_b_1)\n",
    "    fc_dropout_1 = tf.cond(on_train , \n",
    "                           lambda : tf.nn.dropout(fc_output_1 , keep_prob = 0.75) , \n",
    "                           lambda : tf.nn.dropout(fc_output_1 , keep_prob = 1))\n",
    "\n",
    "\n",
    "    # fully connected layer 2\n",
    "    fc_w_2 = weight_variable([1024 , 6])\n",
    "    fc_b_2 = bias_variable([6])\n",
    "    prediction = tf.nn.sigmoid(tf.matmul(fc_dropout_1 , fc_w_2) + fc_b_2) # prediction => (None , 6)\n",
    "\n",
    "\n",
    "    # 因為是輸出經過的是sigmoid，因此cross entropy一定要寫成以下的寫法\n",
    "    ys_ = tf.cast(ys , tf.float32)\n",
    "    cross_entropy = (ys_ * tf.log(prediction + 1e-9)) + ((1 - ys_) * tf.log(1 - prediction + 1e-9)) \n",
    "    cross_entropy = -tf.reduce_mean(tf.reduce_sum(cross_entropy , axis = 1))\n",
    "\n",
    "    # 一筆data中只要有一個預測錯誤，這一筆data就當作預測錯誤\n",
    "    correct = tf.equal(tf.cast(tf.greater_equal(prediction , 0.5) , tf.int32) , tf.cast(ys , tf.int32))\n",
    "    accuracy = tf.reduce_mean(tf.reduce_min(tf.cast(correct , tf.float32) , 1))\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 數據增強\n",
    "aug = ImageDataGenerator(rotation_range = 25, \n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1 ,\n",
    "                         shear_range = 0.2 ,\n",
    "                         zoom_range = 0.2,\n",
    "                         horizontal_flip = True ,\n",
    "                         fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 0\n",
      "train_loss : 4.21\n",
      "train_accuracy : 0.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 25\n",
      "train_loss : 2.93\n",
      "train_accuracy : 18.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 0\n",
      "batch_i : 50\n",
      "train_loss : 0.76\n",
      "train_accuracy : 81.25%\n",
      "\n",
      "******************************\n",
      "epoch_i : 0\n",
      "train_loss_batch_mean : 2.38\n",
      "val_accuracy : 70.90%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 0\n",
      "train_loss : 1.34\n",
      "train_accuracy : 50.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 25\n",
      "train_loss : 0.86\n",
      "train_accuracy : 75.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 1\n",
      "batch_i : 50\n",
      "train_loss : 1.33\n",
      "train_accuracy : 59.38%\n",
      "\n",
      "******************************\n",
      "epoch_i : 1\n",
      "train_loss_batch_mean : 1.14\n",
      "val_accuracy : 80.60%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 0\n",
      "train_loss : 0.72\n",
      "train_accuracy : 78.12%\n",
      "\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 25\n",
      "train_loss : 0.58\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 2\n",
      "batch_i : 50\n",
      "train_loss : 0.52\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "******************************\n",
      "epoch_i : 2\n",
      "train_loss_batch_mean : 0.81\n",
      "val_accuracy : 90.07%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 0, 1, 0, 1, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 0\n",
      "train_loss : 0.42\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 25\n",
      "train_loss : 1.68\n",
      "train_accuracy : 75.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 3\n",
      "batch_i : 50\n",
      "train_loss : 0.49\n",
      "train_accuracy : 84.38%\n",
      "\n",
      "******************************\n",
      "epoch_i : 3\n",
      "train_loss_batch_mean : 0.69\n",
      "val_accuracy : 90.76%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 1, 0, 1, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 0\n",
      "train_loss : 0.46\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 25\n",
      "train_loss : 0.08\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 4\n",
      "batch_i : 50\n",
      "train_loss : 0.94\n",
      "train_accuracy : 75.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 4\n",
      "train_loss_batch_mean : 0.53\n",
      "val_accuracy : 89.15%\n",
      "prediction : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 0\n",
      "train_loss : 0.75\n",
      "train_accuracy : 78.12%\n",
      "\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 25\n",
      "train_loss : 0.45\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 5\n",
      "batch_i : 50\n",
      "train_loss : 0.35\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "******************************\n",
      "epoch_i : 5\n",
      "train_loss_batch_mean : 0.53\n",
      "val_accuracy : 92.38%\n",
      "prediction : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 0\n",
      "train_loss : 0.48\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 25\n",
      "train_loss : 0.37\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 6\n",
      "batch_i : 50\n",
      "train_loss : 0.08\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 6\n",
      "train_loss_batch_mean : 0.43\n",
      "val_accuracy : 91.45%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 0\n",
      "train_loss : 0.35\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 25\n",
      "train_loss : 0.24\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 7\n",
      "batch_i : 50\n",
      "train_loss : 0.46\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "******************************\n",
      "epoch_i : 7\n",
      "train_loss_batch_mean : 0.51\n",
      "val_accuracy : 85.45%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 0\n",
      "train_loss : 0.72\n",
      "train_accuracy : 81.25%\n",
      "\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 25\n",
      "train_loss : 0.56\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 8\n",
      "batch_i : 50\n",
      "train_loss : 0.89\n",
      "train_accuracy : 81.25%\n",
      "\n",
      "******************************\n",
      "epoch_i : 8\n",
      "train_loss_batch_mean : 0.40\n",
      "val_accuracy : 87.99%\n",
      "prediction : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 0\n",
      "train_loss : 0.49\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 25\n",
      "train_loss : 0.34\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 9\n",
      "batch_i : 50\n",
      "train_loss : 0.18\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 9\n",
      "train_loss_batch_mean : 0.40\n",
      "val_accuracy : 94.92%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 10\n",
      "batch_i : 0\n",
      "train_loss : 0.53\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 10\n",
      "batch_i : 25\n",
      "train_loss : 0.18\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 10\n",
      "batch_i : 50\n",
      "train_loss : 0.11\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 10\n",
      "train_loss_batch_mean : 0.34\n",
      "val_accuracy : 93.07%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 11\n",
      "batch_i : 0\n",
      "train_loss : 0.90\n",
      "train_accuracy : 84.38%\n",
      "\n",
      "==============================\n",
      "epoch_i : 11\n",
      "batch_i : 25\n",
      "train_loss : 0.90\n",
      "train_accuracy : 84.38%\n",
      "\n",
      "==============================\n",
      "epoch_i : 11\n",
      "batch_i : 50\n",
      "train_loss : 0.11\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 11\n",
      "train_loss_batch_mean : 0.37\n",
      "val_accuracy : 95.15%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 12\n",
      "batch_i : 0\n",
      "train_loss : 0.37\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 12\n",
      "batch_i : 25\n",
      "train_loss : 0.43\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 12\n",
      "batch_i : 50\n",
      "train_loss : 0.83\n",
      "train_accuracy : 78.12%\n",
      "\n",
      "******************************\n",
      "epoch_i : 12\n",
      "train_loss_batch_mean : 0.54\n",
      "val_accuracy : 92.84%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 13\n",
      "batch_i : 0\n",
      "train_loss : 0.13\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 13\n",
      "batch_i : 25\n",
      "train_loss : 0.39\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 13\n",
      "batch_i : 50\n",
      "train_loss : 0.85\n",
      "train_accuracy : 87.50%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "epoch_i : 13\n",
      "train_loss_batch_mean : 0.34\n",
      "val_accuracy : 94.23%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 14\n",
      "batch_i : 0\n",
      "train_loss : 0.18\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 14\n",
      "batch_i : 25\n",
      "train_loss : 0.19\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 14\n",
      "batch_i : 50\n",
      "train_loss : 0.34\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 14\n",
      "train_loss_batch_mean : 0.29\n",
      "val_accuracy : 94.69%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 15\n",
      "batch_i : 0\n",
      "train_loss : 0.34\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 15\n",
      "batch_i : 25\n",
      "train_loss : 0.79\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 15\n",
      "batch_i : 50\n",
      "train_loss : 0.25\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 15\n",
      "train_loss_batch_mean : 0.40\n",
      "val_accuracy : 94.23%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 16\n",
      "batch_i : 0\n",
      "train_loss : 0.32\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 16\n",
      "batch_i : 25\n",
      "train_loss : 0.21\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 16\n",
      "batch_i : 50\n",
      "train_loss : 0.66\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "******************************\n",
      "epoch_i : 16\n",
      "train_loss_batch_mean : 0.34\n",
      "val_accuracy : 93.07%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 17\n",
      "batch_i : 0\n",
      "train_loss : 0.19\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 17\n",
      "batch_i : 25\n",
      "train_loss : 0.61\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 17\n",
      "batch_i : 50\n",
      "train_loss : 0.29\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 17\n",
      "train_loss_batch_mean : 0.32\n",
      "val_accuracy : 95.15%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 18\n",
      "batch_i : 0\n",
      "train_loss : 0.34\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 18\n",
      "batch_i : 25\n",
      "train_loss : 0.79\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 18\n",
      "batch_i : 50\n",
      "train_loss : 0.29\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 18\n",
      "train_loss_batch_mean : 0.29\n",
      "val_accuracy : 95.15%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 19\n",
      "batch_i : 0\n",
      "train_loss : 0.21\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 19\n",
      "batch_i : 25\n",
      "train_loss : 0.20\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 19\n",
      "batch_i : 50\n",
      "train_loss : 0.36\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "******************************\n",
      "epoch_i : 19\n",
      "train_loss_batch_mean : 0.34\n",
      "val_accuracy : 93.30%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 1]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 20\n",
      "batch_i : 0\n",
      "train_loss : 0.46\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 20\n",
      "batch_i : 25\n",
      "train_loss : 0.34\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 20\n",
      "batch_i : 50\n",
      "train_loss : 0.13\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 20\n",
      "train_loss_batch_mean : 0.28\n",
      "val_accuracy : 94.69%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 21\n",
      "batch_i : 0\n",
      "train_loss : 0.22\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 21\n",
      "batch_i : 25\n",
      "train_loss : 0.99\n",
      "train_accuracy : 84.38%\n",
      "\n",
      "==============================\n",
      "epoch_i : 21\n",
      "batch_i : 50\n",
      "train_loss : 0.31\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "******************************\n",
      "epoch_i : 21\n",
      "train_loss_batch_mean : 0.28\n",
      "val_accuracy : 94.69%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 22\n",
      "batch_i : 0\n",
      "train_loss : 0.09\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 22\n",
      "batch_i : 25\n",
      "train_loss : 0.18\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 22\n",
      "batch_i : 50\n",
      "train_loss : 0.36\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 22\n",
      "train_loss_batch_mean : 0.26\n",
      "val_accuracy : 94.69%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 23\n",
      "batch_i : 0\n",
      "train_loss : 0.15\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 23\n",
      "batch_i : 25\n",
      "train_loss : 0.06\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 23\n",
      "batch_i : 50\n",
      "train_loss : 0.40\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 23\n",
      "train_loss_batch_mean : 0.24\n",
      "val_accuracy : 92.84%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 24\n",
      "batch_i : 0\n",
      "train_loss : 0.24\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 24\n",
      "batch_i : 25\n",
      "train_loss : 0.24\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 24\n",
      "batch_i : 50\n",
      "train_loss : 0.18\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 24\n",
      "train_loss_batch_mean : 0.23\n",
      "val_accuracy : 95.61%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 25\n",
      "batch_i : 0\n",
      "train_loss : 0.15\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 25\n",
      "batch_i : 25\n",
      "train_loss : 0.33\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 25\n",
      "batch_i : 50\n",
      "train_loss : 0.11\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 25\n",
      "train_loss_batch_mean : 0.27\n",
      "val_accuracy : 96.54%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 26\n",
      "batch_i : 0\n",
      "train_loss : 0.19\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 26\n",
      "batch_i : 25\n",
      "train_loss : 0.06\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 26\n",
      "batch_i : 50\n",
      "train_loss : 0.14\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 26\n",
      "train_loss_batch_mean : 0.23\n",
      "val_accuracy : 93.30%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 1, 0, 1, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "epoch_i : 27\n",
      "batch_i : 0\n",
      "train_loss : 0.31\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 27\n",
      "batch_i : 25\n",
      "train_loss : 0.28\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 27\n",
      "batch_i : 50\n",
      "train_loss : 0.30\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 27\n",
      "train_loss_batch_mean : 0.21\n",
      "val_accuracy : 95.84%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 28\n",
      "batch_i : 0\n",
      "train_loss : 0.11\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 28\n",
      "batch_i : 25\n",
      "train_loss : 0.25\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 28\n",
      "batch_i : 50\n",
      "train_loss : 0.18\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 28\n",
      "train_loss_batch_mean : 0.21\n",
      "val_accuracy : 95.84%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 29\n",
      "batch_i : 0\n",
      "train_loss : 0.34\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 29\n",
      "batch_i : 25\n",
      "train_loss : 0.31\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 29\n",
      "batch_i : 50\n",
      "train_loss : 0.45\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "******************************\n",
      "epoch_i : 29\n",
      "train_loss_batch_mean : 0.18\n",
      "val_accuracy : 96.30%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 0, 0, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 30\n",
      "batch_i : 0\n",
      "train_loss : 0.43\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 30\n",
      "batch_i : 25\n",
      "train_loss : 0.12\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 30\n",
      "batch_i : 50\n",
      "train_loss : 0.27\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 30\n",
      "train_loss_batch_mean : 0.21\n",
      "val_accuracy : 95.84%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 31\n",
      "batch_i : 0\n",
      "train_loss : 0.11\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 31\n",
      "batch_i : 25\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 31\n",
      "batch_i : 50\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 31\n",
      "train_loss_batch_mean : 0.18\n",
      "val_accuracy : 96.77%\n",
      "prediction : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 32\n",
      "batch_i : 0\n",
      "train_loss : 0.09\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 32\n",
      "batch_i : 25\n",
      "train_loss : 0.15\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 32\n",
      "batch_i : 50\n",
      "train_loss : 0.12\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 32\n",
      "train_loss_batch_mean : 0.16\n",
      "val_accuracy : 95.15%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 33\n",
      "batch_i : 0\n",
      "train_loss : 0.14\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 33\n",
      "batch_i : 25\n",
      "train_loss : 0.16\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 33\n",
      "batch_i : 50\n",
      "train_loss : 0.11\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 33\n",
      "train_loss_batch_mean : 0.20\n",
      "val_accuracy : 95.61%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 34\n",
      "batch_i : 0\n",
      "train_loss : 0.27\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 34\n",
      "batch_i : 25\n",
      "train_loss : 0.29\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 34\n",
      "batch_i : 50\n",
      "train_loss : 0.36\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 34\n",
      "train_loss_batch_mean : 0.16\n",
      "val_accuracy : 96.54%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 35\n",
      "batch_i : 0\n",
      "train_loss : 0.14\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 35\n",
      "batch_i : 25\n",
      "train_loss : 0.48\n",
      "train_accuracy : 87.50%\n",
      "\n",
      "==============================\n",
      "epoch_i : 35\n",
      "batch_i : 50\n",
      "train_loss : 0.16\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 35\n",
      "train_loss_batch_mean : 0.17\n",
      "val_accuracy : 96.30%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 36\n",
      "batch_i : 0\n",
      "train_loss : 0.24\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 36\n",
      "batch_i : 25\n",
      "train_loss : 0.09\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 36\n",
      "batch_i : 50\n",
      "train_loss : 0.01\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 36\n",
      "train_loss_batch_mean : 0.13\n",
      "val_accuracy : 97.23%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 37\n",
      "batch_i : 0\n",
      "train_loss : 0.00\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 37\n",
      "batch_i : 25\n",
      "train_loss : 0.15\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 37\n",
      "batch_i : 50\n",
      "train_loss : 0.21\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 37\n",
      "train_loss_batch_mean : 0.18\n",
      "val_accuracy : 94.00%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 38\n",
      "batch_i : 0\n",
      "train_loss : 0.06\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 38\n",
      "batch_i : 25\n",
      "train_loss : 0.35\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "==============================\n",
      "epoch_i : 38\n",
      "batch_i : 50\n",
      "train_loss : 0.15\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "******************************\n",
      "epoch_i : 38\n",
      "train_loss_batch_mean : 0.17\n",
      "val_accuracy : 95.84%\n",
      "prediction : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 39\n",
      "batch_i : 0\n",
      "train_loss : 0.11\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 39\n",
      "batch_i : 25\n",
      "train_loss : 0.27\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 39\n",
      "batch_i : 50\n",
      "train_loss : 0.08\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 39\n",
      "train_loss_batch_mean : 0.20\n",
      "val_accuracy : 96.30%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 40\n",
      "batch_i : 0\n",
      "train_loss : 0.08\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 40\n",
      "batch_i : 25\n",
      "train_loss : 0.13\n",
      "train_accuracy : 93.75%\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "epoch_i : 40\n",
      "batch_i : 50\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 40\n",
      "train_loss_batch_mean : 0.18\n",
      "val_accuracy : 96.54%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 0])]\n",
      "target : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 41\n",
      "batch_i : 0\n",
      "train_loss : 0.20\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 41\n",
      "batch_i : 25\n",
      "train_loss : 0.05\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 41\n",
      "batch_i : 50\n",
      "train_loss : 0.08\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 41\n",
      "train_loss_batch_mean : 0.16\n",
      "val_accuracy : 97.23%\n",
      "prediction : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 0, 0, 0, 1]), array([0, 0, 1, 0, 1, 0]), array([1, 0, 0, 1, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 42\n",
      "batch_i : 0\n",
      "train_loss : 0.14\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 42\n",
      "batch_i : 25\n",
      "train_loss : 0.18\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 42\n",
      "batch_i : 50\n",
      "train_loss : 0.24\n",
      "train_accuracy : 90.62%\n",
      "\n",
      "******************************\n",
      "epoch_i : 42\n",
      "train_loss_batch_mean : 0.15\n",
      "val_accuracy : 96.07%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 1, 0, 1, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 43\n",
      "batch_i : 0\n",
      "train_loss : 0.27\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 43\n",
      "batch_i : 25\n",
      "train_loss : 0.42\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 43\n",
      "batch_i : 50\n",
      "train_loss : 0.17\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 43\n",
      "train_loss_batch_mean : 0.16\n",
      "val_accuracy : 95.61%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 44\n",
      "batch_i : 0\n",
      "train_loss : 0.31\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 44\n",
      "batch_i : 25\n",
      "train_loss : 0.28\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 44\n",
      "batch_i : 50\n",
      "train_loss : 0.06\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 44\n",
      "train_loss_batch_mean : 0.26\n",
      "val_accuracy : 92.38%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 45\n",
      "batch_i : 0\n",
      "train_loss : 0.16\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 45\n",
      "batch_i : 25\n",
      "train_loss : 0.13\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 45\n",
      "batch_i : 50\n",
      "train_loss : 0.05\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 45\n",
      "train_loss_batch_mean : 0.17\n",
      "val_accuracy : 96.07%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 46\n",
      "batch_i : 0\n",
      "train_loss : 0.01\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 46\n",
      "batch_i : 25\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 46\n",
      "batch_i : 50\n",
      "train_loss : 0.52\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "******************************\n",
      "epoch_i : 46\n",
      "train_loss_batch_mean : 0.18\n",
      "val_accuracy : 96.77%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 1, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 47\n",
      "batch_i : 0\n",
      "train_loss : 0.06\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 47\n",
      "batch_i : 25\n",
      "train_loss : 0.08\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 47\n",
      "batch_i : 50\n",
      "train_loss : 0.05\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 47\n",
      "train_loss_batch_mean : 0.13\n",
      "val_accuracy : 97.92%\n",
      "prediction : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0])]\n",
      "target : \n",
      "[array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1]), array([0, 1, 1, 0, 0, 0])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 48\n",
      "batch_i : 0\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "==============================\n",
      "epoch_i : 48\n",
      "batch_i : 25\n",
      "train_loss : 0.13\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 48\n",
      "batch_i : 50\n",
      "train_loss : 0.02\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 48\n",
      "train_loss_batch_mean : 0.14\n",
      "val_accuracy : 96.30%\n",
      "prediction : \n",
      "[array([0, 0, 0, 0, 1, 1]), array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "target : \n",
      "[array([0, 0, 1, 0, 1, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 0, 0, 0, 1, 1])]\n",
      "****************************** \n",
      "\n",
      "==============================\n",
      "epoch_i : 49\n",
      "batch_i : 0\n",
      "train_loss : 0.10\n",
      "train_accuracy : 96.88%\n",
      "\n",
      "==============================\n",
      "epoch_i : 49\n",
      "batch_i : 25\n",
      "train_loss : 0.20\n",
      "train_accuracy : 93.75%\n",
      "\n",
      "==============================\n",
      "epoch_i : 49\n",
      "batch_i : 50\n",
      "train_loss : 0.00\n",
      "train_accuracy : 100.00%\n",
      "\n",
      "******************************\n",
      "epoch_i : 49\n",
      "train_loss_batch_mean : 0.17\n",
      "val_accuracy : 96.54%\n",
      "prediction : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "target : \n",
      "[array([1, 0, 0, 1, 0, 0]), array([0, 1, 1, 0, 0, 0]), array([0, 1, 0, 0, 0, 1])]\n",
      "****************************** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batches = 0\n",
    "learning_rate = LR\n",
    "train_loss_mean_record = []\n",
    "val_loss_record = []\n",
    "for epoch_i in range(0 , EPOCHS):\n",
    "    train_loss_temp = []\n",
    "    batches = 0\n",
    "    for batch_i , (x_batch , y_batch) in enumerate(aug.flow(trainX , trainY , shuffle = True , batch_size = 32)):\n",
    "        feed_dict = {xs : x_batch , ys : y_batch , \n",
    "                     on_train : True , \n",
    "                     lr : learning_rate}\n",
    "        train_loss , train_acc , _ = sess.run([cross_entropy , accuracy , train_op] , feed_dict)\n",
    "        train_loss_temp.append(train_loss)\n",
    "        \n",
    "        batches += 1\n",
    "        if batches >= len(trainX) / 32: break\n",
    "    \n",
    "        if batch_i % 25 == 0: \n",
    "            print('=' * 30)\n",
    "            print('epoch_i : {}'.format(epoch_i))\n",
    "            print('batch_i : {}'.format(batch_i))\n",
    "            print('train_loss : {:.2f}'.format(train_loss))\n",
    "            print('train_accuracy : {:.2%}\\n'.format(train_acc))\n",
    "               \n",
    "    feed_dict = {xs : testX , ys : testY , on_train : False}\n",
    "    val_loss , val_acc = sess.run([cross_entropy , accuracy] , feed_dict)    \n",
    "    prediction_value = sess.run(tf.cast(tf.greater_equal(prediction , 0.5) , tf.int32) , feed_dict)\n",
    "    random_index = np.random.choice(len(testX) , 3 , replace = False) # 隨機從testX選3筆image觀看預測結果\n",
    "    \n",
    "    print('*' * 30) \n",
    "    print('epoch_i : {}'.format(epoch_i))               \n",
    "    print('train_loss_batch_mean : {:.2f}'.format(np.array(train_loss_temp).mean()))\n",
    "    print('val_accuracy : {:.2%}'.format(val_acc))\n",
    "    print('prediction : \\n{}'.format(list(prediction_value[random_index])))\n",
    "    print('target : \\n{}'.format(list(testY[random_index].astype(np.int32))))\n",
    "    print('*' * 30 , '\\n')  \n",
    "    \n",
    "    train_loss_mean_record.append(np.array(train_loss_temp).mean())    \n",
    "    val_loss_record.append(val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
